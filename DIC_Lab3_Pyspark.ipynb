{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Sai krishna kanneti                        2. Yashas J Shamraju"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pyspark\n",
    "import pickle\n",
    "sc=pyspark.SparkContext().getOrCreate()\n",
    "sqlContext=pyspark.SQLContext(sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "from pyspark.ml.feature import HashingTF, Tokenizer, StopWordsRemover,OneHotEncoder, StringIndexer, VectorAssembler\n",
    "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df8 = pd.read_csv('data/lab3data.csv',encoding=\"latin-1\")\n",
    "df1 = pd.read_csv('output.csv',encoding=\"latin-1\")\n",
    "df20 = pd.read_csv('data/data_article.csv',encoding=\"latin-1\")\n",
    "# Prepare training documents, which are labeled.\n",
    "\n",
    "df1.columns = ['label', 'text']\n",
    "df8.columns = ['label', 'text']\n",
    "df20.columns = ['label', 'text']\n",
    "#print(df1.columns, df8.columns, df20.columns)\n",
    "df = df1.append([df8, df20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "training = sqlContext.createDataFrame(df, [\"labeli\",\"text\"])\n",
    "train, test = training.randomSplit([0.65, 0.35], seed=12345)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Configure an ML pipeline, which consists of tree stages: tokenizer, hashingTF, and lr.\n",
    "tokenizer = Tokenizer(inputCol=\"text\", outputCol=\"words\")\n",
    "remover = StopWordsRemover(inputCol=tokenizer.getOutputCol(), outputCol=\"filtered\")\n",
    "hashingTF = HashingTF(inputCol=remover.getOutputCol(), outputCol=\"features\")\n",
    "label_stringIdx = StringIndexer(inputCol = \"labeli\", outputCol = \"label\")\n",
    "lr = LogisticRegression(maxIter=10)\n",
    "\n",
    "pipeline = Pipeline(stages=[tokenizer, remover, hashingTF, label_stringIdx, lr])\n",
    "\n",
    "# We now treat the Pipeline as an Estimator, wrapping it in a CrossValidator instance.\n",
    "# This will allow us to jointly choose parameters for all Pipeline stages.\n",
    "# A CrossValidator requires an Estimator, a set of Estimator ParamMaps, and an Evaluator.\n",
    "# We use a ParamGridBuilder to construct a grid of parameters to search over.\n",
    "# With 3 values for hashingTF.numFeatures and 2 values for lr.regParam,\n",
    "# this grid will have 3 x 2 = 6 parameter settings for CrossValidator to choose from.\n",
    "paramGrid = ParamGridBuilder() \\\n",
    "    .addGrid(hashingTF.numFeatures, [10, 100, 1000]) \\\n",
    "    .addGrid(lr.regParam, [0.1, 0.01]) \\\n",
    "    .build()\n",
    "\n",
    "crossval = CrossValidator(estimator=pipeline,\n",
    "                          estimatorParamMaps=paramGrid,\n",
    "                          evaluator=MulticlassClassificationEvaluator(),\n",
    "                          numFolds=2)  # use 3+ folds in practice"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building differnet Pipelines using IDF, HashingTF Separately to check for accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "THE CODE IS COMMENTED AS IT IS NO LONGER USED IN THE PROCESS\n",
    "# Configure an ML pipeline, which consists of tree stages: tokenizer, hashingTF, IDF and lr.\n",
    "tokenizer = Tokenizer(inputCol=\"text\", outputCol=\"words\")\n",
    "remover = StopWordsRemover(inputCol=tokenizer.getOutputCol(), outputCol=\"filtered\")\n",
    "hashingTF = HashingTF(inputCol=remover.getOutputCol(), outputCol=\"features\")\n",
    "idf=IDF(inputCol=hashingTF.getOutputCol(),outputCol='features')\n",
    "label_stringIdx = StringIndexer(inputCol = \"labeli\", outputCol = \"label\")\n",
    "lr = LogisticRegression(maxIter=10)\n",
    "\n",
    "pipeline = Pipeline(stages=[tokenizer, remover, hashingTF, label_stringIdx, lr])\n",
    "\n",
    "# We now treat the Pipeline as an Estimator, wrapping it in a CrossValidator instance.\n",
    "# This will allow us to jointly choose parameters for all Pipeline stages.\n",
    "# A CrossValidator requires an Estimator, a set of Estimator ParamMaps, and an Evaluator.\n",
    "# We use a ParamGridBuilder to construct a grid of parameters to search over.\n",
    "# With 3 values for hashingTF.numFeatures and 2 values for lr.regParam,\n",
    "# this grid will have 3 x 2 = 6 parameter settings for CrossValidator to choose from.\n",
    "paramGrid = ParamGridBuilder() \\\n",
    "    .addGrid(hashingTF.numFeatures, [10, 100, 1000]) \\\n",
    "    .addGrid(lr.regParam, [0.1, 0.01]) \\\n",
    "    .build()\n",
    "\n",
    "crossval = CrossValidator(estimator=pipeline,\n",
    "                          estimatorParamMaps=paramGrid,\n",
    "                          evaluator=MulticlassClassificationEvaluator(),\n",
    "                          numFolds=2)  # use 3+ folds in practice\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Accuracy using HashingTF is more as compared to IDF.(Test Accuracy using HashingTF is 79.26% where as using IDF is 65.62%).\n",
    "so only HashingTF pipeline is further used in all the models and only retained in the downstream pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multi-class Classification using Logistic Regression and crossvalidation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cvModel1 = crossval.fit(train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Crossvalidation model using top 10 words, top 100 words and top 1000 words, different crossfold values and different regularization parameter values: 0.1, 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The test accuracy obtained using Logistic regression:  0.7960420289784099\n"
     ]
    }
   ],
   "source": [
    "# Prepare test documents, which are unlabeled.\n",
    "#test = sqlContext.createDataFrame(test, [\"labeli\", \"text\"])\n",
    "\n",
    "# Make predictions on test documents. cvModel uses the best model found (lrModel).\n",
    "prediction = cvModel.transform(test)\n",
    "selected = prediction.select( \"label\", \"prediction\")\n",
    "evaluator=MulticlassClassificationEvaluator(predictionCol='prediction')\n",
    "test_error=evaluator.evaluate(prediction)\n",
    "print('The test accuracy obtained using Logistic regression is: ',test_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The training accuracy obtained using Logistic regression:  0.8105997920846342\n"
     ]
    }
   ],
   "source": [
    "prediction = cvModel.transform(train)\n",
    "selected = prediction.select( \"label\", \"prediction\")\n",
    "evaluator=MulticlassClassificationEvaluator(predictionCol='prediction')\n",
    "train_error=evaluator.evaluate(prediction)\n",
    "print('The training accuracy obtained using Logistic regression: ',train_error)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multi-class Classification using random Forests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The training accuracy obtained using Random forests:  67.2789\n"
     ]
    }
   ],
   "source": [
    "#Random forest model\n",
    "rf = RandomForestRegressor(featuresCol=\"text\")\n",
    "\n",
    "# Chain indexer and forest in a Pipeline\n",
    "\n",
    "pipeline_rf = Pipeline(stages=[tokenizer, remover, hashingTF, label_stringIdx, rf])\n",
    "\n",
    "# Train model.  This also runs the indexer.\n",
    "model = pipeline_rf.fit(train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test and Training error for Random Forests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The training accuracy obtained using Random forests:  67.2789\n"
     ]
    }
   ],
   "source": [
    "# Make predictions on training dataset.\n",
    "predictions = model.transform(train)\n",
    "\n",
    "evaluator=MulticlassClassificationEvaluator(predictionCol='predictions')\n",
    "train_accuracy=evaluator.evaluate(predictions)\n",
    "print('The training accuracy obtained using Random forests: ',train_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The test accuracy obtained using Random Forests is:  64.284977\n"
     ]
    }
   ],
   "source": [
    "# Make predictions on test documents. cvModel uses the best model found (lrModel).\n",
    "predictions = cvModel.transform(test)\n",
    "evaluator=MulticlassClassificationEvaluator(predictionCol='predictions')\n",
    "test_accuracy=evaluator.evaluate(prediction)\n",
    "print('The test accuracy obtained using Random Forests is: ',test_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test and repeat the feature engineering to further enhance accuracy.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accuracies obtained for Logistic Regression<br>\n",
    "Using HashingTF: <br>\n",
    "    The test accuracy obtained using Logistic regression:  0.7960420289784099<br>\n",
    "    The training accuracy obtained using Logistic regression:  0.8105997920846342<br>\n",
    "Using IDF:<br>\n",
    "    The test accuracy obtained using Logistic regression:  0.65.620640299<br>\n",
    "    The training accuracy obtained using Logistic regression:  0.61.4768546342<br>\n",
    "\n",
    "Accuracies obtained for Random Forests:<br>\n",
    "Using HashingTF:<br>\n",
    "    The training accuracy obtained using Random forests:  67.2789<br>\n",
    "    The test accuracy obtained using Random Forests is:  64.284977<br>\n",
    "Using IDF:<br>\n",
    "    The training accuracy obtained using Random forests:  55.8219<br>\n",
    "    The test accuracy obtained using Random Forests is:  51.54724<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results:<br>\n",
    "\n",
    "    The Logistic Regression has given the best results when compared with 2 different algorithms: Random Forests.<br>\n",
    "    \n",
    "    The HashingTF has given better accuracy values in the pipeline part and used the same for feature engineering while tuning as compared against IDF\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
